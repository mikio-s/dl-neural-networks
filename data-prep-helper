import numpy as np

# Non-interactive plots
%matplotlib inline
import matplotlib.pyplot as plt

import sys
sys.path.append("/home/codio/workspace/.modules")
from helper import *

print("Python version:", sys.version.split(" ")[0])


def load_data(file="heart_disease_train.csv", label=True):
    """
    Returns the data matrix and optionally the corresponding label vector.

    Input:
        file: filename of the dataset
        label: a boolean to decide whether to return the labels or not

    Output:
        X: (numpy array) nxd data matrix of patient attributes
        y: (numpy array) n-dimensional vector of labels (if label=False, y is not returned)
    """
    X = None
    y = None

    import pandas as pd
    df = pd.read_csv(file)
    #with open(file) as f:
    #    entries = [x.rstrip() for x in f.readlines() if len(x) > 0]
    #df = pd.DataFrame(data=entries.data, columns=entries.feature_names)

    
    if label:
        y = df["label"].values
        X = df.drop(columns=["label"]).values
        return X,y
    else:
        X = df.values
        return X
    print(df.head(10))
    #print(df.describe)


X, y = load_data()
print(f"Training data matrix shape: {X.shape}")
print(f"Label vector shape: {y.shape}")


Xtrain, ytrain = load_data()
Xtrain_grader, ytrain_grader = load_data_grader()
Xtest = load_data(file="heart_disease_test.csv", label=False)
Xtest_grader = load_data_grader(file="heart_disease_test.csv", label=False)


def load_data_test1():
    return len(Xtrain) == len(ytrain)


def load_data_test2():
    return len(Xtrain) == len(Xtrain_grader)


def load_data_test3():
    y_unique = np.sort(np.unique(ytrain))
    y_grader_unique = np.sort(np.unique(ytrain_grader))

    if len(y_unique) != len(y_grader_unique):
        return False
    else:
        return np.linalg.norm(y_unique - y_grader_unique) < 1e-7


def load_data_test4():
    return (
        type(Xtrain) == np.ndarray
        and type(ytrain) == np.ndarray
        and type(Xtest) == np.ndarray
    )


def load_data_test5():
    Xtrain.sort()
    Xtrain_grader.sort()
    return np.linalg.norm(Xtrain - Xtrain_grader) < 1e-07


def load_data_test6():
    ntr, dtr = Xtrain.shape
    nte, dte = Xtest.shape
    return dtr == dte


def load_data_test7():
    Xtest.sort()
    Xtest_grader.sort()
    return np.linalg.norm(Xtest - Xtest_grader) < 1e-07


runtest(load_data_test1, "load_data_test1")
runtest(load_data_test2, "load_data_test2")
runtest(load_data_test3, "load_data_test3")
runtest(load_data_test4, "load_data_test4 (Testing for correct types)")
runtest(load_data_test5, "load_data_test5 (Testing training data for correctness)")
runtest(
    load_data_test6,
    "load_data_test6 (training and testing data dimensions should match)",
)
runtest(load_data_test7, "load_data_test7 (Testing test data for correctness)")

def mean_squared_loss(pred, truth):
    """
    Calculates the mean squared loss between predicted and true labels.

    Input:
        pred: n-dimensional vector of predicted labels
        truth: n-dimensional vector of true labels

    Output:
        loss: average squared loss
    """
    return np.mean((pred - truth) ** 2)


#### Regression Tree ####
# Create a regression tree with no restriction on depth
tree = RegressionTree(depth=np.inf)

# Fit/train the regression tree
tree.fit(X, y)

# Use the trained regression tree to make predictions
pred = tree.predict(X)

#### k-Fold Cross Validation ####
# Specify the depths
depths = [1, 3]

# Generate 5 folds for X data
indices = generate_kFold(n=X.shape[0], k=5)

# Find best depth across the folds
best_depth, training_losses, validation_losses = cross_validation(X, y, depths, indices)


def make_prediction():
    """
    Loads the training and test sets, trains a regression tree,
    and outputs predictions for the test set.

    Output:
        prediction: the prediction of your classifier on the heart_disease_test.csv
    """
    prediction = None
    Xtrain, ytrain = load_data(file="heart_disease_train.csv", label=True)
    ytrain = ytrain > 0
    Xtest = load_data(file="heart_disease_test.csv", label=False)

    depths = [1, 3]
    indices = generate_kFold(n=X.shape[0], k=5)
    best_depth, training_losses, validation_losses = cross_validation(X, y, depths, indices)
    tree = RegressionTree(depth=best_depth)
    tree.fit(Xtrain, ytrain)
    prediction = tree.predict(Xtest)
    
    return prediction


def make_prediction_test():
    """
    Test for your make_prediction function
    """
    truth = np.array(
        [
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,
            1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1
        ]
    )
    pred = make_prediction()
    loss = mean_squared_loss(pred, truth)
    return loss < 0.18


runtest(make_prediction_test, "make_prediction_test")

      
